{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PyTorch-GPU",
      "language": "python",
      "name": "pyt-gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "8-SciProg_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pDnSshCXD-ZL",
        "2JDTirUfD-Zf",
        "vICVTE1wD-Zq",
        "wDNQLaL6D-Zu",
        "hNbj9oDlD-aS",
        "3kRdaQe6D-ab",
        "5t7iYj2eD-an",
        "VY6m7c0qD-bQ"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "59ac615d27ac4a8a9e16f26d226f2a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c17884873f104da681a369aef07cd7ed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4b234d4d1ed449a69c7a707f156abf09",
              "IPY_MODEL_ccc84a48be774014a1fbca524529d3f2"
            ]
          }
        },
        "c17884873f104da681a369aef07cd7ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b234d4d1ed449a69c7a707f156abf09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3ece9a70cd474541854c4e53f7ac32c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e8a029703274f02916c51f0414bf9c6"
          }
        },
        "ccc84a48be774014a1fbca524529d3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bdac665fdaa14c03880719df12671f5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:20&lt;00:00, 1722625.10it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2b5c9f6a0b449a5aa04aa2c143a093c"
          }
        },
        "3ece9a70cd474541854c4e53f7ac32c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e8a029703274f02916c51f0414bf9c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bdac665fdaa14c03880719df12671f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2b5c9f6a0b449a5aa04aa2c143a093c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "feb6cbb0108e49f8a64d62371e2f0717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eb2ff08432ce42889b9283135388dd2a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cca56bc8507546928fa759d6200e5dc5",
              "IPY_MODEL_d5eb2a80c81b40b3840778d4bd7901a9"
            ]
          }
        },
        "eb2ff08432ce42889b9283135388dd2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cca56bc8507546928fa759d6200e5dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7b3cfc902cf44ac0af7a4a7703eeac67",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0748f10e07c445fb8db186488d3f4872"
          }
        },
        "d5eb2a80c81b40b3840778d4bd7901a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b92f1d855f694190978d134a05b638ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/28881 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4adeb1848d0f45809200fcf7ec4e83d0"
          }
        },
        "7b3cfc902cf44ac0af7a4a7703eeac67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0748f10e07c445fb8db186488d3f4872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b92f1d855f694190978d134a05b638ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4adeb1848d0f45809200fcf7ec4e83d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2665ef3e02f644a1ab533dab13266c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c51aa6d3d3a54b15b7f01a7154e97230",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d3a58daa0572413fafb07e18df147ab2",
              "IPY_MODEL_170efb9d9772481d9e3d59a8b0cc0b66"
            ]
          }
        },
        "c51aa6d3d3a54b15b7f01a7154e97230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3a58daa0572413fafb07e18df147ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_595e6ce405154cca9cc3153db6044d42",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b992aac426545809a37ddc4d8ac01fd"
          }
        },
        "170efb9d9772481d9e3d59a8b0cc0b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ad73e1f567f49ab8e3411cdd572aae4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:18&lt;00:00, 536622.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68f5123da480472d95dc3fe5f5e4f453"
          }
        },
        "595e6ce405154cca9cc3153db6044d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b992aac426545809a37ddc4d8ac01fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ad73e1f567f49ab8e3411cdd572aae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68f5123da480472d95dc3fe5f5e4f453": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e40d1aa0116a462da610741c3a9c65a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_406e01c5c1aa414297db5516060e0af7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_afa9a9964b924b9aae9fb4bec7684cb2",
              "IPY_MODEL_0020949becbf48ac9cdddaf4f075ce5c"
            ]
          }
        },
        "406e01c5c1aa414297db5516060e0af7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afa9a9964b924b9aae9fb4bec7684cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ccddde088f8443e69d3ec102bae7eb5d",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb535e2a37e04b4785b53964c8fe3ac9"
          }
        },
        "0020949becbf48ac9cdddaf4f075ce5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4803189e444b4c908266204e6d79e906",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/4542 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04ca90ad283642849438872b4b382aff"
          }
        },
        "ccddde088f8443e69d3ec102bae7eb5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb535e2a37e04b4785b53964c8fe3ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4803189e444b4c908266204e6d79e906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04ca90ad283642849438872b4b382aff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nochwysid/CSE5008-SP/blob/main/8_SciProg_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VNIH93hD-Ya"
      },
      "source": [
        "# Lecture 8 - PyTorch\n",
        "\n",
        "This will be the final lecture, today we will first have a brief introduction of deep learning, then we will look at some basics of using PyTorch to implement some simple models in deep learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-fCZYu2D-Yc"
      },
      "source": [
        "## Deep Learning Libraries\n",
        "\n",
        "There are many deep learning libraries available, the most common ones for python are\n",
        "\n",
        "- TensorFlow, Keras\n",
        "- PyTorch\n",
        "\n",
        "Working with tensorflow requires going into lot of details of the contruction of the computation graph, whereas Keras is a higher level interface for tensorflow. Tensorflow is very popular in the industry and good for production code.\n",
        "\n",
        "PyTorch can be used as low level interface, but is much more user-friendly than tensorflow, but it also has a higher level interface. Pytorch is more popular in the research community."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzUDYHi8D-Yd"
      },
      "source": [
        "## Main features that any deep learning library should provide\n",
        "\n",
        "No matter what library or language you use, the main features provided by a deep learning library are \n",
        "1. Use the GPU to speed up computation \n",
        "2. Ability to do automatic differentiation\n",
        "3. Useful library functions for common architectures and optimization algorithms\n",
        "\n",
        "### PyTorch\n",
        "We will look at all of the above in pytorch.\n",
        "The best way to think about pytorch is that its numpy + GPU + autograd.\n",
        "\n",
        "You can install it with\n",
        "\n",
        "```conda install pytorch```.\n",
        "\n",
        "Alternatively (and recommended), run this notebook in Google Colab-- it provides an environment with all of the PyTorch dependencies plus a GPU free of charge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCdvNHW0D-Ye"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpWzZewHD-Yi"
      },
      "source": [
        "The equivalent object to numpy arrays in pytorch are called tensors, but they are just multidimensional arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t78yenP1D-Yj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459162ce-5b70-4c8c-c100-c548647b60d2"
      },
      "source": [
        "torch.tensor([2,3,4,5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efg1UeizD-Ym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b49716-6da4-41aa-905a-5c7ea13e9398"
      },
      "source": [
        "torch.zeros((5,5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BlufhDpD-Yp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c415d205-70ba-4a2e-96db-4255ebfcd56a"
      },
      "source": [
        "x = torch.ones((5,5))\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acgFdW_4D-Yr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e58c91-6aaf-4dbb-da6c-b716347b711f"
      },
      "source": [
        "2*x + 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7., 7., 7., 7., 7.],\n",
              "        [7., 7., 7., 7., 7.],\n",
              "        [7., 7., 7., 7., 7.],\n",
              "        [7., 7., 7., 7., 7.],\n",
              "        [7., 7., 7., 7., 7.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwCz7O1wD-Yu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a0048d-068d-4e4d-a0c0-31c5ab04bc42"
      },
      "source": [
        "torch.randn(5,5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.2004,  1.9679,  1.2333, -0.9784, -1.6882],\n",
              "        [ 1.3808, -0.8077,  1.3718, -0.2011,  0.9329],\n",
              "        [ 1.3031, -1.0330, -0.9047, -1.1807, -0.7573],\n",
              "        [ 1.4894, -0.3231, -0.1198,  0.1358,  1.8188],\n",
              "        [-0.1027, -0.0832, -1.1348,  0.6314,  0.1946]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fHiY5VKD-Yw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a94944-a089-422c-b7d8-41f49e1d713d"
      },
      "source": [
        "x = torch.rand(25)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7859, 0.1342, 0.6402, 0.1283, 0.6151, 0.4641, 0.2077, 0.3854, 0.8694,\n",
              "        0.6901, 0.6535, 0.0040, 0.3261, 0.5783, 0.6023, 0.1285, 0.0301, 0.5156,\n",
              "        0.4088, 0.5968, 0.9702, 0.9029, 0.2511, 0.0179, 0.2987])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_QKyI7hD-Yz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1614d1af-d5ff-4da3-e1a2-67d067b4d2a1"
      },
      "source": [
        "x=x.reshape(-1,5)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7859, 0.1342, 0.6402, 0.1283, 0.6151],\n",
              "        [0.4641, 0.2077, 0.3854, 0.8694, 0.6901],\n",
              "        [0.6535, 0.0040, 0.3261, 0.5783, 0.6023],\n",
              "        [0.1285, 0.0301, 0.5156, 0.4088, 0.5968],\n",
              "        [0.9702, 0.9029, 0.2511, 0.0179, 0.2987]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLKjs14-D-Y3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f96c045-725d-4ec6-840a-bee9875da9d6"
      },
      "source": [
        "x.shape "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn9fwJoSD-Y5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fdb9b32-3752-41a9-bb17-136d1a3c21b8"
      },
      "source": [
        "print(torch.arange(10))\n",
        "print(torch.eye(5))\n",
        "print(torch.linspace(0,1,10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1.]])\n",
            "tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
            "        1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cix7EXwSD-Y7"
      },
      "source": [
        "Some functions are a bit different"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BukQIL5D-Y8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6fda71-eb63-4e4b-c4ee-fb3cc9e177ea"
      },
      "source": [
        "A = torch.rand(5,5)\n",
        "#or A = torch.rand((5,5))\n",
        "x = torch.ones(5,1)\n",
        "#x = torch.rand((5,1))\n",
        "A@x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3930],\n",
              "        [2.4147],\n",
              "        [3.1479],\n",
              "        [2.1666],\n",
              "        [3.0608]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YHvvy4D-Y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e06b44f-da24-4b82-f94d-089d251a55b0"
      },
      "source": [
        "A = np.random.rand(5,5)\n",
        "x = np.ones((5,1))\n",
        "A@x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.28515591],\n",
              "       [2.12895405],\n",
              "       [2.86067858],\n",
              "       [2.90461326],\n",
              "       [2.25966029]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpEwcH-JD-ZA"
      },
      "source": [
        "You can convert tensors to a numpy array that shares its memory with the pytorch tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MquNPK71D-ZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a118e40-2780-4ffb-e1a2-6050fd11efbf"
      },
      "source": [
        "x = torch.ones(5,5)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtmMcKn2bSvP",
        "outputId": "d5e77fbb-a8f8-46b8-b6b1-3bb16c26d4e6"
      },
      "source": [
        "y = np.ones((5,5))\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOeMqFrOD-ZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80649f75-acaa-4569-f851-a072394be7a7"
      },
      "source": [
        "xn = x.numpy()\n",
        "xn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZlG0x9xD-ZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14128869-0572-4fc0-9afb-23f2db8e7379"
      },
      "source": [
        "xn[4,2]=10\n",
        "xn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  1.,  1.,  1.,  1.],\n",
              "       [ 1.,  1.,  1.,  1.,  1.],\n",
              "       [ 1.,  1.,  1.,  1.,  1.],\n",
              "       [ 1.,  1.,  1.,  1.,  1.],\n",
              "       [ 1.,  1., 10.,  1.,  1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN6qJIsID-ZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bea3e4d-c2b6-49f5-ce26-d7c95b77cb26"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  1.,  1.,  1.,  1.],\n",
              "        [ 1.,  1.,  1.,  1.,  1.],\n",
              "        [ 1.,  1.,  1.,  1.,  1.],\n",
              "        [ 1.,  1.,  1.,  1.,  1.],\n",
              "        [ 1.,  1., 10.,  1.,  1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDnSshCXD-ZL"
      },
      "source": [
        "### Using the GPU\n",
        "\n",
        "The GPU (Graphical Processing Unit) is a separate processing unit that is specialized to handle bulk computations required for rendering high quality graphics. It mainly consists of a large number of processor cores that are individually very slow, but because of their sheer number (around 2000) they can churn through computations very quickly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmJ0hjO5D-ZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf0d5ce-4c20-4efe-c389-54ec0e33330a"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0kadMeJD-ZN"
      },
      "source": [
        "Installing the GPU drivers and the CUDA toolkit can be quite messy, so if you just want to experiment with GPUs and deep learning libraries, you can use [Google colaboratory](https://colab.research.google.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCtE0kLaD-ZO"
      },
      "source": [
        "gpu = torch.device(\"cuda\")\n",
        "cpu = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESIE5J08D-ZS"
      },
      "source": [
        "A = torch.rand(100,100)\n",
        "B = torch.rand(100,100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6VNz5SzD-ZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b5956d-4dbc-4dd2-84f7-5821589abda7"
      },
      "source": [
        "A@B"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[30.7644, 27.8900, 25.2460,  ..., 26.5461, 26.8385, 26.3531],\n",
              "        [28.6269, 25.9650, 25.7306,  ..., 24.1777, 27.4599, 25.0372],\n",
              "        [25.7387, 25.6085, 25.6574,  ..., 23.6575, 24.7603, 22.6737],\n",
              "        ...,\n",
              "        [27.0243, 25.6721, 25.2278,  ..., 22.8266, 26.6797, 24.2812],\n",
              "        [31.1906, 27.0809, 26.5625,  ..., 25.6647, 27.6765, 26.8511],\n",
              "        [28.8057, 25.3955, 24.5333,  ..., 25.5837, 26.4371, 24.9363]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXjtNNqtD-ZW"
      },
      "source": [
        "A_gpu = A.to(gpu)\n",
        "B_gpu = B.to(gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krIHa3ErD-ZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e7237b5-1654-42a6-aa45-b31b68199140"
      },
      "source": [
        "A_gpu@B_gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[30.7644, 27.8900, 25.2460,  ..., 26.5461, 26.8385, 26.3530],\n",
              "        [28.6269, 25.9650, 25.7306,  ..., 24.1777, 27.4599, 25.0372],\n",
              "        [25.7387, 25.6085, 25.6574,  ..., 23.6575, 24.7603, 22.6737],\n",
              "        ...,\n",
              "        [27.0243, 25.6721, 25.2278,  ..., 22.8266, 26.6797, 24.2812],\n",
              "        [31.1906, 27.0809, 26.5625,  ..., 25.6647, 27.6765, 26.8511],\n",
              "        [28.8057, 25.3955, 24.5333,  ..., 25.5837, 26.4371, 24.9363]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sox7ng2OD-ZZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "465e9863-e3ef-4b31-c9b8-f4fdf42f20e9"
      },
      "source": [
        "A@B_gpu #this won't work!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-2e3381049b9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mB_gpu\u001b[0m \u001b[0;31m#this won't work!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Tensor for 'out' is on CPU, Tensor for argument #1 'self' is on CPU, but expected them to be on GPU (while checking arguments for addmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5oi8M-GD-Zc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc69fcf0-f92b-4a86-a375-da9d6ca48edf"
      },
      "source": [
        "C_gpu = A_gpu@B_gpu\n",
        "C = C_gpu.to(cpu)\n",
        "C"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[30.7644, 27.8900, 25.2460,  ..., 26.5461, 26.8385, 26.3530],\n",
              "        [28.6269, 25.9650, 25.7306,  ..., 24.1777, 27.4599, 25.0372],\n",
              "        [25.7387, 25.6085, 25.6574,  ..., 23.6575, 24.7603, 22.6737],\n",
              "        ...,\n",
              "        [27.0243, 25.6721, 25.2278,  ..., 22.8266, 26.6797, 24.2812],\n",
              "        [31.1906, 27.0809, 26.5625,  ..., 25.6647, 27.6765, 26.8511],\n",
              "        [28.8057, 25.3955, 24.5333,  ..., 25.5837, 26.4371, 24.9363]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JDTirUfD-Zf"
      },
      "source": [
        "### GPU - CPU memory transfer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc4PxyqTD-Zf"
      },
      "source": [
        "big_mat = torch.rand(20000,20000);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE0StFx6D-Zh"
      },
      "source": [
        "big_mat_gpu = big_mat.to(gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEI_-PmOD-Zj"
      },
      "source": [
        "big_mat= big_mat_gpu.to(cpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx6a7G8UD-Zl"
      },
      "source": [
        "del big_mat_gpu\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUt6M95HD-Zn"
      },
      "source": [
        "del big_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vICVTE1wD-Zq"
      },
      "source": [
        "## Speedup from GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4raRnuw1D-Zr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b1d7a1-d9ed-4dc9-b835-e776bd6a4cf5"
      },
      "source": [
        "%%timeit\n",
        "A = torch.rand(3000,3000)\n",
        "B = torch.rand(3000,3000)\n",
        "C = torch.zeros(3000,3000)\n",
        "C.copy_(B)\n",
        "for i in range(5):\n",
        "    C=torch.mm(A,C)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 3.16 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch47eB6OD-Zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "088d9d60-4794-4378-8481-e89f564643bb"
      },
      "source": [
        "%%timeit\n",
        "A = torch.rand(3000,3000, device = gpu)\n",
        "B = torch.rand(3000,3000, device = gpu)\n",
        "C = torch.zeros(3000,3000, device = gpu)\n",
        "C.copy_(B)\n",
        "for i in range(5):\n",
        "    C=torch.mm(A,C)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 76.7 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDNQLaL6D-Zu"
      },
      "source": [
        "## Automatic Differentiation\n",
        "\n",
        "PyTorch uses dynamic computation graphs to compute the gradients of the parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r6mfgjHD-Zv"
      },
      "source": [
        "x = torch.tensor([2.0])\n",
        "m = torch.tensor([5.0], requires_grad = True)\n",
        "c = torch.tensor([2.0], requires_grad = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eezGUNqXD-Zy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f204d163-a911-4573-e1ab-469d2589e031"
      },
      "source": [
        "y = m*x + c\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_Y_WzasD-Z0"
      },
      "source": [
        "Define an error for your function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r7oYMHFD-Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ed622a-30bb-4f99-addb-4fa40363de35"
      },
      "source": [
        "loss = torch.norm( y - 13)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., grad_fn=<CopyBackwards>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OuhWukrD-Z3"
      },
      "source": [
        "m.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMhtVXAhD-Z5"
      },
      "source": [
        "Calling `x.backward()` on any tensor forces pytorch to compute all the gradients of the tensors used to compute `x` which had the `requires_grad` flag set to `True`. The computed gradient will be stored in the `.grad` property of the tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PIU90uoD-Z5"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYbns6g4D-Z7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81706a04-5267-477e-f9a8-7a9acf45832e"
      },
      "source": [
        "m.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MYesARFD-Z9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22358b58-6c82-4401-bd27-a9636f9eca0a"
      },
      "source": [
        "c.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDhPOJHRD-aA"
      },
      "source": [
        "with torch.no_grad():\n",
        "    m -= 0.01 * m.grad\n",
        "    c -= 0.3 * c.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TlUBDHaD-aC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f4d19b5-9690-47b0-a9fd-2a2024d027ed"
      },
      "source": [
        "m,c"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5.0200], requires_grad=True), tensor([2.3000], requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj85MTj2D-aF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d66ee817-097a-4988-d6b2-ba293af0d59e"
      },
      "source": [
        "m.grad, c.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-2.]), tensor([-1.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3UbDFA7D-aJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38322203-f9ca-47ce-ad2d-85461b9a9a59"
      },
      "source": [
        "m.grad.zero_()\n",
        "c.grad.zero_()\n",
        "\n",
        "m.grad, c.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.]), tensor([0.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNgA5bqxD-aL"
      },
      "source": [
        "y = m*x + c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhEnrtmQD-aN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6132cd9-9bba-4c38-c00c-a21516bd2156"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.3400], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJYE5aRpD-aO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da838e0d-6d9a-44d2-aa5e-e903ee27889e"
      },
      "source": [
        "loss = torch.norm( y - 13)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6600, grad_fn=<CopyBackwards>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBLYqopxD-aQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9957c903-d989-40c5-b9d6-7b9e15666a31"
      },
      "source": [
        "loss.backward()\n",
        "m.grad, c.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-4.]), tensor([-2.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNbj9oDlD-aS"
      },
      "source": [
        "### Making it more compact"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlQ60VuqD-aS"
      },
      "source": [
        "def model_fn(x,m,c):\n",
        "    return m*x + c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zZHeiwJD-aV"
      },
      "source": [
        "def loss_fn(y,yt):\n",
        "    return torch.norm(y-yt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7drmZAzD-aX"
      },
      "source": [
        "m = torch.tensor([5.0], requires_grad = True)\n",
        "c = torch.tensor([2.0], requires_grad = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSogMXf-D-aY"
      },
      "source": [
        "x = torch.tensor([2.0])\n",
        "yt = torch.tensor([13.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77BNsdU-D-aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1ffb0bc-00f9-406c-c6cc-d03bdc6984e1"
      },
      "source": [
        "y = model_fn(x,m,c)\n",
        "loss = loss_fn(y,yt)\n",
        "loss.backward()\n",
        "with torch.no_grad():\n",
        "    m -= 0.005 * m.grad\n",
        "    c -= 0.005 * c.grad\n",
        "m.grad.zero_()\n",
        "c.grad.zero_()\n",
        "\n",
        "print( f\" m = {m}\\n c = {c}\\n y = {y}\\n loss = {loss}\")\n",
        "#note that 'loss' indicates the loss for the previous m,c values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " m = tensor([5.4100], requires_grad=True)\n",
            " c = tensor([2.2050], requires_grad=True)\n",
            " y = tensor([13.0000], grad_fn=<AddBackward0>)\n",
            " loss = 6.67572021484375e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kRdaQe6D-ab"
      },
      "source": [
        "### Slightly more complicated problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alq94bPxD-ac"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HdYDtWDD-ae"
      },
      "source": [
        "def model_fn(x,m,c):\n",
        "    return m@x + c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Cvos0BD-af"
      },
      "source": [
        "def loss_fn(y,yt):\n",
        "    return torch.norm(y-yt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vCjbW7HD-ah"
      },
      "source": [
        "m = torch.rand((5,5), requires_grad = True)\n",
        "c = torch.ones((5,1), requires_grad = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsITRCClD-ai"
      },
      "source": [
        "x = torch.randn(5,100)\n",
        "yt = torch.randn(1,100)\n",
        "losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFs5CphAD-al",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f43ca04-68f6-45e7-f19d-aa7e190ae51d"
      },
      "source": [
        "for i in range(1000):\n",
        "  y = model_fn(x,m,c)\n",
        "  loss = loss_fn(y,yt)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "      m -= 0.05 * m.grad\n",
        "      c -= 0.05 * c.grad\n",
        "  m.grad.zero_()\n",
        "  c.grad.zero_()\n",
        "\n",
        "  losses+=[loss.item()]\n",
        "  print( f\"loss = {loss}\")\n",
        "  plt.plot(losses);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss = 43.690364837646484\n",
            "loss = 39.99468994140625\n",
            "loss = 36.60718536376953\n",
            "loss = 33.58106231689453\n",
            "loss = 30.965354919433594\n",
            "loss = 28.793943405151367\n",
            "loss = 27.073562622070312\n",
            "loss = 25.776756286621094\n",
            "loss = 24.845256805419922\n",
            "loss = 24.203672409057617\n",
            "loss = 23.776012420654297\n",
            "loss = 23.49741554260254\n",
            "loss = 23.318466186523438\n",
            "loss = 23.20437240600586\n",
            "loss = 23.131803512573242\n",
            "loss = 23.085588455200195\n",
            "loss = 23.05607795715332\n",
            "loss = 23.03713035583496\n",
            "loss = 23.0248966217041\n",
            "loss = 23.016956329345703\n",
            "loss = 23.011764526367188\n",
            "loss = 23.00832748413086\n",
            "loss = 23.006061553955078\n",
            "loss = 23.00454330444336\n",
            "loss = 23.003517150878906\n",
            "loss = 23.002826690673828\n",
            "loss = 23.002355575561523\n",
            "loss = 23.002023696899414\n",
            "loss = 23.001798629760742\n",
            "loss = 23.001636505126953\n",
            "loss = 23.001529693603516\n",
            "loss = 23.001445770263672\n",
            "loss = 23.001399993896484\n",
            "loss = 23.00135040283203\n",
            "loss = 23.00132179260254\n",
            "loss = 23.001312255859375\n",
            "loss = 23.00128746032715\n",
            "loss = 23.001283645629883\n",
            "loss = 23.001266479492188\n",
            "loss = 23.00127601623535\n",
            "loss = 23.001266479492188\n",
            "loss = 23.001258850097656\n",
            "loss = 23.001256942749023\n",
            "loss = 23.00126075744629\n",
            "loss = 23.001256942749023\n",
            "loss = 23.00126075744629\n",
            "loss = 23.001258850097656\n",
            "loss = 23.001253128051758\n",
            "loss = 23.001256942749023\n",
            "loss = 23.001256942749023\n",
            "loss = 23.001251220703125\n",
            "loss = 23.001251220703125\n",
            "loss = 23.00125503540039\n",
            "loss = 23.001256942749023\n",
            "loss = 23.001249313354492\n",
            "loss = 23.001253128051758\n",
            "loss = 23.001251220703125\n",
            "loss = 23.001253128051758\n",
            "loss = 23.001251220703125\n",
            "loss = 23.001253128051758\n",
            "loss = 23.001249313354492\n",
            "loss = 23.00124740600586\n",
            "loss = 23.001249313354492\n",
            "loss = 23.001249313354492\n",
            "loss = 23.00125503540039\n",
            "loss = 23.001253128051758\n",
            "loss = 23.00125503540039\n",
            "loss = 23.001253128051758\n",
            "loss = 23.001256942749023\n",
            "loss = 23.001253128051758\n",
            "loss = 23.001253128051758\n",
            "loss = 23.001256942749023\n",
            "loss = 23.001256942749023\n",
            "loss = 23.001256942749023\n",
            "loss = 23.001253128051758\n",
            "loss = 23.001253128051758\n",
            "loss = 23.001253128051758\n",
            "loss = 23.00125503540039\n",
            "loss = 23.001256942749023\n",
            "loss = 23.001253128051758\n",
            "loss = 23.001251220703125\n",
            "loss = 23.001249313354492\n",
            "loss = 23.001249313354492\n",
            "loss = 23.001249313354492\n",
            "loss = 23.001249313354492\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.001249313354492\n",
            "loss = 23.001249313354492\n",
            "loss = 23.001249313354492\n",
            "loss = 23.001249313354492\n",
            "loss = 23.001249313354492\n",
            "loss = 23.001249313354492\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.00124740600586\n",
            "loss = 23.001245498657227\n",
            "loss = 23.00124740600586\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n",
            "loss = 23.001245498657227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t7iYj2eD-an"
      },
      "source": [
        "## Using Library functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xg-kywmD-an"
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(5, 5),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(5, 5),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OocRUb9D-ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b7c499-2211-496d-99ac-635090c05191"
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.1616, -0.2809, -0.1754,  0.3181, -0.4102],\n",
              "         [-0.3271,  0.3970,  0.3911,  0.3099, -0.3973],\n",
              "         [ 0.0751,  0.0095,  0.2664, -0.1789,  0.1173],\n",
              "         [ 0.1278, -0.4385,  0.1929, -0.1575, -0.2441],\n",
              "         [-0.3250, -0.3798,  0.0452, -0.2026,  0.2446]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.3556,  0.1627,  0.2884, -0.0073,  0.3771], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.4454, -0.2138,  0.1116,  0.2253, -0.1806],\n",
              "         [-0.0161,  0.1084,  0.2893, -0.0940,  0.3490],\n",
              "         [-0.3674, -0.1149,  0.0186,  0.0138, -0.2781],\n",
              "         [ 0.4465, -0.0371,  0.2036,  0.0836,  0.3737],\n",
              "         [ 0.0666, -0.1404,  0.2701, -0.0838, -0.4311]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.3714, -0.3381,  0.2672, -0.3060,  0.1305], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgBOzYv5D-aq"
      },
      "source": [
        "loss_fn = torch.nn.MSELoss(reduction='sum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bdGByKKD-as"
      },
      "source": [
        "x = torch.randn(100,5)\n",
        "yt = torch.randn(100,1)\n",
        "losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KupJGFEFD-at"
      },
      "source": [
        "Using the optim package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ac8_-reD-au"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqRB-phKD-aw"
      },
      "source": [
        "torch.optim."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtdxXUcRD-az",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1ef730c-c0e7-4daf-83b1-2a0211b5c5eb"
      },
      "source": [
        "for i in range(1000):\n",
        "    y = model(x)\n",
        "    loss = loss_fn(y,yt)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    losses+=[loss.item()]\n",
        "    print( f\"loss = {loss}\")\n",
        "plt.plot(losses);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([100, 1])) that is different to the input size (torch.Size([100, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss = 475.00885009765625\n",
            "loss = 457.6354064941406\n",
            "loss = 446.7303771972656\n",
            "loss = 439.40887451171875\n",
            "loss = 434.2867736816406\n",
            "loss = 430.36029052734375\n",
            "loss = 427.0753173828125\n",
            "loss = 423.9656982421875\n",
            "loss = 421.0675354003906\n",
            "loss = 417.72747802734375\n",
            "loss = 413.99908447265625\n",
            "loss = 410.58642578125\n",
            "loss = 408.0198974609375\n",
            "loss = 406.3163757324219\n",
            "loss = 405.16448974609375\n",
            "loss = 404.47528076171875\n",
            "loss = 403.4824523925781\n",
            "loss = 401.96563720703125\n",
            "loss = 400.1684875488281\n",
            "loss = 398.3601989746094\n",
            "loss = 396.7138977050781\n",
            "loss = 395.2435302734375\n",
            "loss = 393.963623046875\n",
            "loss = 393.1605529785156\n",
            "loss = 392.3914794921875\n",
            "loss = 391.5802307128906\n",
            "loss = 390.8912353515625\n",
            "loss = 390.0355224609375\n",
            "loss = 389.2562561035156\n",
            "loss = 388.0806884765625\n",
            "loss = 387.06390380859375\n",
            "loss = 386.3192443847656\n",
            "loss = 385.572509765625\n",
            "loss = 384.78814697265625\n",
            "loss = 384.0393981933594\n",
            "loss = 382.9290771484375\n",
            "loss = 381.7249755859375\n",
            "loss = 380.3483581542969\n",
            "loss = 378.7856140136719\n",
            "loss = 377.67425537109375\n",
            "loss = 376.50994873046875\n",
            "loss = 375.0694580078125\n",
            "loss = 373.5876159667969\n",
            "loss = 372.5028381347656\n",
            "loss = 371.7119140625\n",
            "loss = 370.8174743652344\n",
            "loss = 369.82379150390625\n",
            "loss = 368.78533935546875\n",
            "loss = 368.2249450683594\n",
            "loss = 367.9147644042969\n",
            "loss = 367.091552734375\n",
            "loss = 365.8788757324219\n",
            "loss = 364.3987731933594\n",
            "loss = 362.84197998046875\n",
            "loss = 361.5356750488281\n",
            "loss = 360.0990295410156\n",
            "loss = 358.4461975097656\n",
            "loss = 357.04779052734375\n",
            "loss = 355.5932922363281\n",
            "loss = 353.9310607910156\n",
            "loss = 352.21173095703125\n",
            "loss = 350.77130126953125\n",
            "loss = 349.4786071777344\n",
            "loss = 347.96649169921875\n",
            "loss = 346.35809326171875\n",
            "loss = 344.82763671875\n",
            "loss = 343.5827331542969\n",
            "loss = 342.80426025390625\n",
            "loss = 342.2279052734375\n",
            "loss = 341.89349365234375\n",
            "loss = 341.796142578125\n",
            "loss = 341.6949768066406\n",
            "loss = 341.3353576660156\n",
            "loss = 341.0645446777344\n",
            "loss = 340.7132568359375\n",
            "loss = 340.151611328125\n",
            "loss = 339.1251220703125\n",
            "loss = 337.8283996582031\n",
            "loss = 336.4216003417969\n",
            "loss = 335.06884765625\n",
            "loss = 333.7616271972656\n",
            "loss = 332.6157531738281\n",
            "loss = 331.69024658203125\n",
            "loss = 330.8809814453125\n",
            "loss = 330.2870178222656\n",
            "loss = 329.63458251953125\n",
            "loss = 329.0271911621094\n",
            "loss = 328.5097961425781\n",
            "loss = 328.2821350097656\n",
            "loss = 327.78753662109375\n",
            "loss = 327.346435546875\n",
            "loss = 326.76739501953125\n",
            "loss = 326.1260986328125\n",
            "loss = 325.9341125488281\n",
            "loss = 325.3797912597656\n",
            "loss = 324.8497314453125\n",
            "loss = 324.4078369140625\n",
            "loss = 323.8114013671875\n",
            "loss = 322.9509582519531\n",
            "loss = 322.16644287109375\n",
            "loss = 321.5673522949219\n",
            "loss = 320.8841247558594\n",
            "loss = 320.0833435058594\n",
            "loss = 319.300048828125\n",
            "loss = 318.60675048828125\n",
            "loss = 318.1025390625\n",
            "loss = 317.3856506347656\n",
            "loss = 316.9729919433594\n",
            "loss = 316.8771667480469\n",
            "loss = 316.5921325683594\n",
            "loss = 316.5097351074219\n",
            "loss = 316.2182312011719\n",
            "loss = 315.59259033203125\n",
            "loss = 314.89642333984375\n",
            "loss = 314.2856750488281\n",
            "loss = 313.70806884765625\n",
            "loss = 313.4990234375\n",
            "loss = 313.60400390625\n",
            "loss = 313.3712158203125\n",
            "loss = 313.3959045410156\n",
            "loss = 312.9630126953125\n",
            "loss = 312.1941223144531\n",
            "loss = 312.2388000488281\n",
            "loss = 312.2141418457031\n",
            "loss = 312.1265869140625\n",
            "loss = 311.85406494140625\n",
            "loss = 311.3311767578125\n",
            "loss = 310.61590576171875\n",
            "loss = 309.8121337890625\n",
            "loss = 308.98907470703125\n",
            "loss = 308.05224609375\n",
            "loss = 307.27105712890625\n",
            "loss = 306.6249694824219\n",
            "loss = 305.8963928222656\n",
            "loss = 305.3455505371094\n",
            "loss = 305.4256896972656\n",
            "loss = 305.2857971191406\n",
            "loss = 305.09637451171875\n",
            "loss = 304.9684753417969\n",
            "loss = 304.65093994140625\n",
            "loss = 304.4912109375\n",
            "loss = 304.1598815917969\n",
            "loss = 303.9662780761719\n",
            "loss = 303.6945495605469\n",
            "loss = 303.4992370605469\n",
            "loss = 303.4561462402344\n",
            "loss = 303.0281982421875\n",
            "loss = 302.8177185058594\n",
            "loss = 302.67718505859375\n",
            "loss = 302.6714782714844\n",
            "loss = 302.60540771484375\n",
            "loss = 302.3984375\n",
            "loss = 302.2615661621094\n",
            "loss = 302.2543029785156\n",
            "loss = 302.16827392578125\n",
            "loss = 302.1455993652344\n",
            "loss = 302.32135009765625\n",
            "loss = 302.160400390625\n",
            "loss = 301.9495544433594\n",
            "loss = 301.945556640625\n",
            "loss = 301.934814453125\n",
            "loss = 301.98236083984375\n",
            "loss = 301.83935546875\n",
            "loss = 301.7016296386719\n",
            "loss = 301.7508544921875\n",
            "loss = 301.88031005859375\n",
            "loss = 301.7730407714844\n",
            "loss = 301.55767822265625\n",
            "loss = 301.75982666015625\n",
            "loss = 301.7379150390625\n",
            "loss = 301.3709716796875\n",
            "loss = 301.5108642578125\n",
            "loss = 301.6434326171875\n",
            "loss = 301.63134765625\n",
            "loss = 301.35546875\n",
            "loss = 301.3835144042969\n",
            "loss = 301.58367919921875\n",
            "loss = 301.49407958984375\n",
            "loss = 301.35760498046875\n",
            "loss = 301.2574462890625\n",
            "loss = 301.22222900390625\n",
            "loss = 301.2564697265625\n",
            "loss = 301.3154296875\n",
            "loss = 301.14239501953125\n",
            "loss = 301.09027099609375\n",
            "loss = 301.2572937011719\n",
            "loss = 301.22113037109375\n",
            "loss = 301.2474670410156\n",
            "loss = 301.2013244628906\n",
            "loss = 300.9958801269531\n",
            "loss = 301.04681396484375\n",
            "loss = 301.3020324707031\n",
            "loss = 301.1953125\n",
            "loss = 301.0751953125\n",
            "loss = 301.0913391113281\n",
            "loss = 301.11578369140625\n",
            "loss = 300.97930908203125\n",
            "loss = 300.9647521972656\n",
            "loss = 301.0688781738281\n",
            "loss = 301.0906982421875\n",
            "loss = 300.8848571777344\n",
            "loss = 300.97271728515625\n",
            "loss = 301.0391540527344\n",
            "loss = 300.9298095703125\n",
            "loss = 300.805908203125\n",
            "loss = 301.0210266113281\n",
            "loss = 300.9466247558594\n",
            "loss = 300.83843994140625\n",
            "loss = 300.9833679199219\n",
            "loss = 301.0390625\n",
            "loss = 300.8843994140625\n",
            "loss = 300.8746337890625\n",
            "loss = 301.091552734375\n",
            "loss = 300.8746337890625\n",
            "loss = 300.8075866699219\n",
            "loss = 300.7138366699219\n",
            "loss = 300.5690612792969\n",
            "loss = 300.65576171875\n",
            "loss = 300.8962707519531\n",
            "loss = 300.5789489746094\n",
            "loss = 300.6237487792969\n",
            "loss = 300.58612060546875\n",
            "loss = 300.6980285644531\n",
            "loss = 300.5504455566406\n",
            "loss = 300.5318298339844\n",
            "loss = 300.6257019042969\n",
            "loss = 300.4245300292969\n",
            "loss = 300.20654296875\n",
            "loss = 300.4752197265625\n",
            "loss = 300.32598876953125\n",
            "loss = 300.3397521972656\n",
            "loss = 300.2799987792969\n",
            "loss = 300.30230712890625\n",
            "loss = 300.3249206542969\n",
            "loss = 300.2674255371094\n",
            "loss = 300.25152587890625\n",
            "loss = 300.2637939453125\n",
            "loss = 300.5280456542969\n",
            "loss = 300.3486022949219\n",
            "loss = 300.40313720703125\n",
            "loss = 300.2541809082031\n",
            "loss = 300.31317138671875\n",
            "loss = 300.412353515625\n",
            "loss = 300.3921813964844\n",
            "loss = 300.2599182128906\n",
            "loss = 300.2561950683594\n",
            "loss = 300.2253112792969\n",
            "loss = 300.10833740234375\n",
            "loss = 300.3801574707031\n",
            "loss = 300.551513671875\n",
            "loss = 300.51904296875\n",
            "loss = 300.1545715332031\n",
            "loss = 300.4516296386719\n",
            "loss = 300.4290466308594\n",
            "loss = 300.33709716796875\n",
            "loss = 300.3838806152344\n",
            "loss = 300.2866516113281\n",
            "loss = 300.1361389160156\n",
            "loss = 300.0848083496094\n",
            "loss = 300.3660583496094\n",
            "loss = 300.18475341796875\n",
            "loss = 300.1390380859375\n",
            "loss = 300.1517333984375\n",
            "loss = 300.2951354980469\n",
            "loss = 300.2772216796875\n",
            "loss = 300.108642578125\n",
            "loss = 300.1697998046875\n",
            "loss = 300.1977844238281\n",
            "loss = 300.09881591796875\n",
            "loss = 300.1389465332031\n",
            "loss = 300.306884765625\n",
            "loss = 300.0092468261719\n",
            "loss = 300.2186279296875\n",
            "loss = 300.1086730957031\n",
            "loss = 300.05047607421875\n",
            "loss = 300.0896911621094\n",
            "loss = 300.13262939453125\n",
            "loss = 300.17071533203125\n",
            "loss = 300.2181396484375\n",
            "loss = 300.3334655761719\n",
            "loss = 300.2394714355469\n",
            "loss = 300.1425476074219\n",
            "loss = 300.240478515625\n",
            "loss = 300.27154541015625\n",
            "loss = 300.20855712890625\n",
            "loss = 300.2528991699219\n",
            "loss = 300.15625\n",
            "loss = 300.3398742675781\n",
            "loss = 300.267333984375\n",
            "loss = 300.2374267578125\n",
            "loss = 300.23974609375\n",
            "loss = 300.1623229980469\n",
            "loss = 300.1597595214844\n",
            "loss = 300.3177185058594\n",
            "loss = 300.2981872558594\n",
            "loss = 300.2364501953125\n",
            "loss = 300.15924072265625\n",
            "loss = 300.14410400390625\n",
            "loss = 300.0561828613281\n",
            "loss = 300.0576171875\n",
            "loss = 300.11407470703125\n",
            "loss = 300.3203125\n",
            "loss = 300.2644958496094\n",
            "loss = 300.260986328125\n",
            "loss = 300.2201232910156\n",
            "loss = 300.1415710449219\n",
            "loss = 300.084228515625\n",
            "loss = 300.10546875\n",
            "loss = 300.1009826660156\n",
            "loss = 300.3262939453125\n",
            "loss = 300.1452331542969\n",
            "loss = 300.0341796875\n",
            "loss = 300.21405029296875\n",
            "loss = 300.1882629394531\n",
            "loss = 300.09857177734375\n",
            "loss = 300.04541015625\n",
            "loss = 299.9772033691406\n",
            "loss = 300.2644348144531\n",
            "loss = 299.9947509765625\n",
            "loss = 300.0287170410156\n",
            "loss = 300.04986572265625\n",
            "loss = 300.01617431640625\n",
            "loss = 299.9125671386719\n",
            "loss = 300.0343322753906\n",
            "loss = 300.05389404296875\n",
            "loss = 300.2148742675781\n",
            "loss = 300.1101379394531\n",
            "loss = 300.17059326171875\n",
            "loss = 300.0676574707031\n",
            "loss = 300.1016845703125\n",
            "loss = 300.0736083984375\n",
            "loss = 300.113525390625\n",
            "loss = 300.0998229980469\n",
            "loss = 300.2624816894531\n",
            "loss = 300.10552978515625\n",
            "loss = 300.2544250488281\n",
            "loss = 300.2038879394531\n",
            "loss = 300.24078369140625\n",
            "loss = 300.2064208984375\n",
            "loss = 300.2887268066406\n",
            "loss = 300.2005615234375\n",
            "loss = 300.16326904296875\n",
            "loss = 300.14599609375\n",
            "loss = 300.169677734375\n",
            "loss = 300.1897888183594\n",
            "loss = 300.16156005859375\n",
            "loss = 300.0821228027344\n",
            "loss = 300.04656982421875\n",
            "loss = 300.127685546875\n",
            "loss = 300.1784973144531\n",
            "loss = 300.18389892578125\n",
            "loss = 300.0839538574219\n",
            "loss = 300.0890197753906\n",
            "loss = 300.1353454589844\n",
            "loss = 300.0601806640625\n",
            "loss = 300.0657043457031\n",
            "loss = 300.1528015136719\n",
            "loss = 300.2156982421875\n",
            "loss = 300.150634765625\n",
            "loss = 300.134765625\n",
            "loss = 300.10064697265625\n",
            "loss = 300.1060791015625\n",
            "loss = 299.9720153808594\n",
            "loss = 300.22998046875\n",
            "loss = 300.1081237792969\n",
            "loss = 300.0657653808594\n",
            "loss = 300.1809387207031\n",
            "loss = 300.13299560546875\n",
            "loss = 300.3181457519531\n",
            "loss = 300.0430908203125\n",
            "loss = 300.0417785644531\n",
            "loss = 300.0360412597656\n",
            "loss = 300.2044677734375\n",
            "loss = 299.9801940917969\n",
            "loss = 300.0863037109375\n",
            "loss = 300.1220703125\n",
            "loss = 300.1102600097656\n",
            "loss = 300.1202087402344\n",
            "loss = 299.9992370605469\n",
            "loss = 300.0846252441406\n",
            "loss = 300.025146484375\n",
            "loss = 300.08184814453125\n",
            "loss = 300.13739013671875\n",
            "loss = 300.0094299316406\n",
            "loss = 300.2108459472656\n",
            "loss = 300.11834716796875\n",
            "loss = 300.0235595703125\n",
            "loss = 300.2013854980469\n",
            "loss = 300.1336975097656\n",
            "loss = 299.92364501953125\n",
            "loss = 300.0431823730469\n",
            "loss = 300.1319580078125\n",
            "loss = 300.0120849609375\n",
            "loss = 300.084228515625\n",
            "loss = 300.0472106933594\n",
            "loss = 300.007568359375\n",
            "loss = 300.0000915527344\n",
            "loss = 299.9964599609375\n",
            "loss = 300.19207763671875\n",
            "loss = 300.2120056152344\n",
            "loss = 300.2127990722656\n",
            "loss = 300.07696533203125\n",
            "loss = 300.048828125\n",
            "loss = 299.97454833984375\n",
            "loss = 300.1078186035156\n",
            "loss = 300.0338134765625\n",
            "loss = 300.08160400390625\n",
            "loss = 300.1647033691406\n",
            "loss = 300.1004943847656\n",
            "loss = 300.1989440917969\n",
            "loss = 300.27618408203125\n",
            "loss = 300.39996337890625\n",
            "loss = 300.21673583984375\n",
            "loss = 300.14727783203125\n",
            "loss = 300.00921630859375\n",
            "loss = 300.17529296875\n",
            "loss = 300.08428955078125\n",
            "loss = 300.0959167480469\n",
            "loss = 300.05224609375\n",
            "loss = 300.06793212890625\n",
            "loss = 300.0342712402344\n",
            "loss = 300.0875244140625\n",
            "loss = 299.9473876953125\n",
            "loss = 300.03228759765625\n",
            "loss = 300.0244140625\n",
            "loss = 299.93316650390625\n",
            "loss = 299.9762878417969\n",
            "loss = 299.9488525390625\n",
            "loss = 300.2974548339844\n",
            "loss = 299.996337890625\n",
            "loss = 300.21112060546875\n",
            "loss = 300.090087890625\n",
            "loss = 300.20904541015625\n",
            "loss = 300.3359680175781\n",
            "loss = 300.2398681640625\n",
            "loss = 300.3506164550781\n",
            "loss = 300.23699951171875\n",
            "loss = 300.16058349609375\n",
            "loss = 300.2369079589844\n",
            "loss = 300.1646728515625\n",
            "loss = 300.1437072753906\n",
            "loss = 300.08428955078125\n",
            "loss = 300.3219299316406\n",
            "loss = 300.12115478515625\n",
            "loss = 300.099609375\n",
            "loss = 300.09844970703125\n",
            "loss = 300.15277099609375\n",
            "loss = 299.88470458984375\n",
            "loss = 300.1599426269531\n",
            "loss = 300.1143493652344\n",
            "loss = 300.0532531738281\n",
            "loss = 300.08251953125\n",
            "loss = 300.1203918457031\n",
            "loss = 299.98876953125\n",
            "loss = 300.03924560546875\n",
            "loss = 300.0849914550781\n",
            "loss = 300.0914611816406\n",
            "loss = 300.16455078125\n",
            "loss = 300.2547607421875\n",
            "loss = 300.0940856933594\n",
            "loss = 299.96173095703125\n",
            "loss = 299.9794006347656\n",
            "loss = 300.1793518066406\n",
            "loss = 300.16973876953125\n",
            "loss = 300.21136474609375\n",
            "loss = 300.1170959472656\n",
            "loss = 300.1770324707031\n",
            "loss = 300.067138671875\n",
            "loss = 300.1109313964844\n",
            "loss = 300.170166015625\n",
            "loss = 300.0852355957031\n",
            "loss = 300.0446472167969\n",
            "loss = 299.99383544921875\n",
            "loss = 300.22088623046875\n",
            "loss = 299.94573974609375\n",
            "loss = 300.06390380859375\n",
            "loss = 300.1695861816406\n",
            "loss = 300.03363037109375\n",
            "loss = 299.9984130859375\n",
            "loss = 300.1992492675781\n",
            "loss = 300.22149658203125\n",
            "loss = 300.10968017578125\n",
            "loss = 300.1341247558594\n",
            "loss = 300.08563232421875\n",
            "loss = 300.11932373046875\n",
            "loss = 300.00189208984375\n",
            "loss = 299.9951171875\n",
            "loss = 299.98590087890625\n",
            "loss = 300.0802001953125\n",
            "loss = 300.0956726074219\n",
            "loss = 300.0331115722656\n",
            "loss = 299.9974060058594\n",
            "loss = 300.13165283203125\n",
            "loss = 300.1903076171875\n",
            "loss = 300.1524658203125\n",
            "loss = 300.2498779296875\n",
            "loss = 300.19219970703125\n",
            "loss = 300.16546630859375\n",
            "loss = 300.208251953125\n",
            "loss = 300.0244445800781\n",
            "loss = 299.9183349609375\n",
            "loss = 300.1122741699219\n",
            "loss = 300.2054138183594\n",
            "loss = 300.11334228515625\n",
            "loss = 299.9991149902344\n",
            "loss = 300.02032470703125\n",
            "loss = 300.02783203125\n",
            "loss = 300.00921630859375\n",
            "loss = 300.1320495605469\n",
            "loss = 300.1535949707031\n",
            "loss = 300.0718994140625\n",
            "loss = 300.0750732421875\n",
            "loss = 300.1134033203125\n",
            "loss = 300.2597351074219\n",
            "loss = 300.1523132324219\n",
            "loss = 300.1081848144531\n",
            "loss = 300.1298522949219\n",
            "loss = 300.3633728027344\n",
            "loss = 300.21295166015625\n",
            "loss = 300.26220703125\n",
            "loss = 300.11053466796875\n",
            "loss = 300.1690673828125\n",
            "loss = 299.9934387207031\n",
            "loss = 300.0078125\n",
            "loss = 300.0856018066406\n",
            "loss = 300.16552734375\n",
            "loss = 299.94708251953125\n",
            "loss = 300.0196228027344\n",
            "loss = 300.1408386230469\n",
            "loss = 300.1337890625\n",
            "loss = 300.0683898925781\n",
            "loss = 300.0628356933594\n",
            "loss = 300.0055236816406\n",
            "loss = 300.3564758300781\n",
            "loss = 300.19769287109375\n",
            "loss = 300.1932678222656\n",
            "loss = 300.3016357421875\n",
            "loss = 300.166748046875\n",
            "loss = 300.04736328125\n",
            "loss = 300.1799011230469\n",
            "loss = 300.0492248535156\n",
            "loss = 299.96856689453125\n",
            "loss = 300.20587158203125\n",
            "loss = 300.1195373535156\n",
            "loss = 300.124755859375\n",
            "loss = 300.0882263183594\n",
            "loss = 300.1451416015625\n",
            "loss = 300.1615905761719\n",
            "loss = 300.0543518066406\n",
            "loss = 300.1370849609375\n",
            "loss = 300.20989990234375\n",
            "loss = 300.0894470214844\n",
            "loss = 299.9927978515625\n",
            "loss = 300.0385437011719\n",
            "loss = 300.26239013671875\n",
            "loss = 300.00250244140625\n",
            "loss = 300.093017578125\n",
            "loss = 300.21087646484375\n",
            "loss = 300.233154296875\n",
            "loss = 300.280029296875\n",
            "loss = 300.27349853515625\n",
            "loss = 300.2915344238281\n",
            "loss = 300.16839599609375\n",
            "loss = 300.1099548339844\n",
            "loss = 300.11358642578125\n",
            "loss = 300.0404357910156\n",
            "loss = 300.139892578125\n",
            "loss = 300.1070251464844\n",
            "loss = 300.0947265625\n",
            "loss = 300.219970703125\n",
            "loss = 300.0234680175781\n",
            "loss = 300.0125427246094\n",
            "loss = 300.0306396484375\n",
            "loss = 300.36895751953125\n",
            "loss = 300.13848876953125\n",
            "loss = 300.1485290527344\n",
            "loss = 300.1739196777344\n",
            "loss = 300.02215576171875\n",
            "loss = 300.06005859375\n",
            "loss = 300.11248779296875\n",
            "loss = 299.96942138671875\n",
            "loss = 300.069580078125\n",
            "loss = 300.0433044433594\n",
            "loss = 300.0193176269531\n",
            "loss = 300.022705078125\n",
            "loss = 299.99591064453125\n",
            "loss = 300.0852966308594\n",
            "loss = 299.99029541015625\n",
            "loss = 300.0268249511719\n",
            "loss = 300.0172424316406\n",
            "loss = 300.0533447265625\n",
            "loss = 300.1251220703125\n",
            "loss = 300.1780090332031\n",
            "loss = 300.0453186035156\n",
            "loss = 300.0270080566406\n",
            "loss = 300.10198974609375\n",
            "loss = 299.9354248046875\n",
            "loss = 300.2017822265625\n",
            "loss = 300.27392578125\n",
            "loss = 300.2087097167969\n",
            "loss = 300.102294921875\n",
            "loss = 300.1394348144531\n",
            "loss = 300.20477294921875\n",
            "loss = 300.0491638183594\n",
            "loss = 300.1119689941406\n",
            "loss = 300.1136474609375\n",
            "loss = 300.00653076171875\n",
            "loss = 300.0832214355469\n",
            "loss = 300.1004638671875\n",
            "loss = 299.9873046875\n",
            "loss = 300.00323486328125\n",
            "loss = 300.0611572265625\n",
            "loss = 299.9298095703125\n",
            "loss = 300.012451171875\n",
            "loss = 300.0467834472656\n",
            "loss = 300.19219970703125\n",
            "loss = 300.06134033203125\n",
            "loss = 300.0558776855469\n",
            "loss = 300.067626953125\n",
            "loss = 300.03839111328125\n",
            "loss = 299.9900207519531\n",
            "loss = 299.9026794433594\n",
            "loss = 299.94854736328125\n",
            "loss = 300.0281982421875\n",
            "loss = 300.01715087890625\n",
            "loss = 300.1338195800781\n",
            "loss = 300.0235900878906\n",
            "loss = 300.0959167480469\n",
            "loss = 299.99713134765625\n",
            "loss = 300.0129089355469\n",
            "loss = 300.0005187988281\n",
            "loss = 299.96051025390625\n",
            "loss = 300.0825500488281\n",
            "loss = 300.09515380859375\n",
            "loss = 300.10552978515625\n",
            "loss = 300.0711975097656\n",
            "loss = 300.0596923828125\n",
            "loss = 300.1582336425781\n",
            "loss = 299.95794677734375\n",
            "loss = 300.0698547363281\n",
            "loss = 299.985595703125\n",
            "loss = 300.03369140625\n",
            "loss = 300.0570983886719\n",
            "loss = 300.0006408691406\n",
            "loss = 299.99359130859375\n",
            "loss = 300.008544921875\n",
            "loss = 299.9969787597656\n",
            "loss = 300.01141357421875\n",
            "loss = 300.0568542480469\n",
            "loss = 299.942626953125\n",
            "loss = 299.966064453125\n",
            "loss = 300.0580139160156\n",
            "loss = 300.1047668457031\n",
            "loss = 300.1995544433594\n",
            "loss = 300.15924072265625\n",
            "loss = 300.111083984375\n",
            "loss = 300.0928955078125\n",
            "loss = 300.1441955566406\n",
            "loss = 300.09881591796875\n",
            "loss = 300.0198669433594\n",
            "loss = 300.1324157714844\n",
            "loss = 300.2664794921875\n",
            "loss = 300.069580078125\n",
            "loss = 300.0949401855469\n",
            "loss = 300.0892333984375\n",
            "loss = 300.02349853515625\n",
            "loss = 299.93017578125\n",
            "loss = 299.9477844238281\n",
            "loss = 300.19189453125\n",
            "loss = 300.1581115722656\n",
            "loss = 300.02325439453125\n",
            "loss = 300.0811767578125\n",
            "loss = 300.2578430175781\n",
            "loss = 300.19866943359375\n",
            "loss = 300.0686950683594\n",
            "loss = 300.08428955078125\n",
            "loss = 300.10546875\n",
            "loss = 300.2850036621094\n",
            "loss = 300.0409240722656\n",
            "loss = 300.09423828125\n",
            "loss = 300.12896728515625\n",
            "loss = 300.05023193359375\n",
            "loss = 300.0313415527344\n",
            "loss = 299.9760437011719\n",
            "loss = 300.0897521972656\n",
            "loss = 300.39556884765625\n",
            "loss = 300.1090393066406\n",
            "loss = 300.1397399902344\n",
            "loss = 300.1197509765625\n",
            "loss = 300.048828125\n",
            "loss = 299.9895324707031\n",
            "loss = 299.9377136230469\n",
            "loss = 299.9794616699219\n",
            "loss = 300.0447692871094\n",
            "loss = 300.0057373046875\n",
            "loss = 300.07232666015625\n",
            "loss = 300.09295654296875\n",
            "loss = 300.1673889160156\n",
            "loss = 300.0935974121094\n",
            "loss = 299.9754638671875\n",
            "loss = 300.0103454589844\n",
            "loss = 300.06488037109375\n",
            "loss = 300.14263916015625\n",
            "loss = 299.96221923828125\n",
            "loss = 300.0671081542969\n",
            "loss = 300.00146484375\n",
            "loss = 300.00616455078125\n",
            "loss = 300.0888671875\n",
            "loss = 300.0682373046875\n",
            "loss = 300.0356750488281\n",
            "loss = 300.06011962890625\n",
            "loss = 300.1343688964844\n",
            "loss = 300.1426696777344\n",
            "loss = 300.025146484375\n",
            "loss = 300.0525817871094\n",
            "loss = 300.0394592285156\n",
            "loss = 299.9662170410156\n",
            "loss = 299.8507080078125\n",
            "loss = 300.0634765625\n",
            "loss = 300.02459716796875\n",
            "loss = 299.9236755371094\n",
            "loss = 300.14947509765625\n",
            "loss = 299.9501647949219\n",
            "loss = 300.0131530761719\n",
            "loss = 300.0664978027344\n",
            "loss = 300.1552734375\n",
            "loss = 300.1125793457031\n",
            "loss = 300.1988830566406\n",
            "loss = 300.18035888671875\n",
            "loss = 300.0744934082031\n",
            "loss = 299.9848327636719\n",
            "loss = 300.0257263183594\n",
            "loss = 300.0762023925781\n",
            "loss = 299.9508056640625\n",
            "loss = 300.06781005859375\n",
            "loss = 299.9593811035156\n",
            "loss = 299.94775390625\n",
            "loss = 300.12176513671875\n",
            "loss = 300.0618896484375\n",
            "loss = 300.06878662109375\n",
            "loss = 300.10211181640625\n",
            "loss = 300.2059326171875\n",
            "loss = 300.1148986816406\n",
            "loss = 300.087646484375\n",
            "loss = 300.0942077636719\n",
            "loss = 299.98443603515625\n",
            "loss = 300.0830383300781\n",
            "loss = 299.985595703125\n",
            "loss = 300.0343017578125\n",
            "loss = 300.1398010253906\n",
            "loss = 300.1184387207031\n",
            "loss = 300.1557922363281\n",
            "loss = 300.2406005859375\n",
            "loss = 300.1081848144531\n",
            "loss = 300.0912170410156\n",
            "loss = 300.0876770019531\n",
            "loss = 300.0617370605469\n",
            "loss = 300.09228515625\n",
            "loss = 300.3344421386719\n",
            "loss = 300.14990234375\n",
            "loss = 300.1303405761719\n",
            "loss = 300.15338134765625\n",
            "loss = 300.2313537597656\n",
            "loss = 300.2353515625\n",
            "loss = 300.1018981933594\n",
            "loss = 300.203857421875\n",
            "loss = 300.1326904296875\n",
            "loss = 300.1869812011719\n",
            "loss = 300.0657043457031\n",
            "loss = 300.14361572265625\n",
            "loss = 300.134521484375\n",
            "loss = 299.9190979003906\n",
            "loss = 300.0870361328125\n",
            "loss = 299.92535400390625\n",
            "loss = 299.92919921875\n",
            "loss = 299.9498596191406\n",
            "loss = 300.0068664550781\n",
            "loss = 299.97491455078125\n",
            "loss = 300.0061340332031\n",
            "loss = 299.9913024902344\n",
            "loss = 299.9427185058594\n",
            "loss = 299.9741516113281\n",
            "loss = 299.99847412109375\n",
            "loss = 299.98828125\n",
            "loss = 299.9521179199219\n",
            "loss = 299.90673828125\n",
            "loss = 300.0393981933594\n",
            "loss = 300.0763854980469\n",
            "loss = 300.1124267578125\n",
            "loss = 300.05157470703125\n",
            "loss = 300.1006164550781\n",
            "loss = 299.9838562011719\n",
            "loss = 299.98931884765625\n",
            "loss = 299.95867919921875\n",
            "loss = 300.1194152832031\n",
            "loss = 299.87493896484375\n",
            "loss = 299.897705078125\n",
            "loss = 300.0537109375\n",
            "loss = 299.8868408203125\n",
            "loss = 299.9041748046875\n",
            "loss = 300.0040283203125\n",
            "loss = 300.0304870605469\n",
            "loss = 300.1572570800781\n",
            "loss = 300.0052490234375\n",
            "loss = 300.0323486328125\n",
            "loss = 300.0273742675781\n",
            "loss = 299.9799499511719\n",
            "loss = 299.95263671875\n",
            "loss = 299.9651184082031\n",
            "loss = 300.03411865234375\n",
            "loss = 300.011474609375\n",
            "loss = 300.071533203125\n",
            "loss = 299.9857482910156\n",
            "loss = 299.9931640625\n",
            "loss = 300.06658935546875\n",
            "loss = 299.96600341796875\n",
            "loss = 299.93133544921875\n",
            "loss = 300.060546875\n",
            "loss = 299.9760437011719\n",
            "loss = 300.08984375\n",
            "loss = 300.0508117675781\n",
            "loss = 300.01934814453125\n",
            "loss = 300.0517883300781\n",
            "loss = 299.97412109375\n",
            "loss = 300.0954284667969\n",
            "loss = 300.06488037109375\n",
            "loss = 300.0770263671875\n",
            "loss = 299.97552490234375\n",
            "loss = 300.04156494140625\n",
            "loss = 300.02313232421875\n",
            "loss = 299.9812927246094\n",
            "loss = 300.028564453125\n",
            "loss = 299.9620361328125\n",
            "loss = 299.9714050292969\n",
            "loss = 300.0759582519531\n",
            "loss = 299.9754333496094\n",
            "loss = 299.974853515625\n",
            "loss = 299.9233093261719\n",
            "loss = 300.0319519042969\n",
            "loss = 299.9587097167969\n",
            "loss = 299.93621826171875\n",
            "loss = 299.9410400390625\n",
            "loss = 300.12689208984375\n",
            "loss = 300.1009826660156\n",
            "loss = 300.2084655761719\n",
            "loss = 300.0773620605469\n",
            "loss = 300.06390380859375\n",
            "loss = 300.21649169921875\n",
            "loss = 300.1256103515625\n",
            "loss = 299.99566650390625\n",
            "loss = 300.1979064941406\n",
            "loss = 300.0796203613281\n",
            "loss = 300.1998291015625\n",
            "loss = 300.0937805175781\n",
            "loss = 300.04949951171875\n",
            "loss = 300.1300048828125\n",
            "loss = 300.1415100097656\n",
            "loss = 300.0921325683594\n",
            "loss = 300.089111328125\n",
            "loss = 300.0145568847656\n",
            "loss = 300.04052734375\n",
            "loss = 300.0490417480469\n",
            "loss = 300.0184631347656\n",
            "loss = 300.06988525390625\n",
            "loss = 300.0924377441406\n",
            "loss = 300.19744873046875\n",
            "loss = 300.171630859375\n",
            "loss = 300.0735168457031\n",
            "loss = 300.05426025390625\n",
            "loss = 300.0067443847656\n",
            "loss = 300.2337951660156\n",
            "loss = 300.1334228515625\n",
            "loss = 300.0875244140625\n",
            "loss = 300.0233154296875\n",
            "loss = 299.90887451171875\n",
            "loss = 300.091796875\n",
            "loss = 300.132568359375\n",
            "loss = 299.9188232421875\n",
            "loss = 300.0259704589844\n",
            "loss = 300.01153564453125\n",
            "loss = 299.9841003417969\n",
            "loss = 300.152099609375\n",
            "loss = 300.0924377441406\n",
            "loss = 299.99560546875\n",
            "loss = 300.0458679199219\n",
            "loss = 300.02215576171875\n",
            "loss = 300.0523986816406\n",
            "loss = 300.0353088378906\n",
            "loss = 299.99267578125\n",
            "loss = 299.9767761230469\n",
            "loss = 300.06268310546875\n",
            "loss = 300.045654296875\n",
            "loss = 300.1785888671875\n",
            "loss = 300.0600891113281\n",
            "loss = 300.0758056640625\n",
            "loss = 300.1394348144531\n",
            "loss = 300.0177917480469\n",
            "loss = 299.9841003417969\n",
            "loss = 299.9658203125\n",
            "loss = 300.09674072265625\n",
            "loss = 300.1739196777344\n",
            "loss = 300.0128173828125\n",
            "loss = 300.0972595214844\n",
            "loss = 300.0132751464844\n",
            "loss = 300.0012512207031\n",
            "loss = 300.23638916015625\n",
            "loss = 299.9443359375\n",
            "loss = 300.07958984375\n",
            "loss = 300.1171875\n",
            "loss = 300.0735778808594\n",
            "loss = 299.98358154296875\n",
            "loss = 299.9920654296875\n",
            "loss = 300.1509094238281\n",
            "loss = 300.0715026855469\n",
            "loss = 300.1258850097656\n",
            "loss = 300.08819580078125\n",
            "loss = 300.03033447265625\n",
            "loss = 300.1295166015625\n",
            "loss = 300.041015625\n",
            "loss = 300.129150390625\n",
            "loss = 300.10205078125\n",
            "loss = 299.9958801269531\n",
            "loss = 299.9448547363281\n",
            "loss = 300.0221252441406\n",
            "loss = 300.1368408203125\n",
            "loss = 300.0190734863281\n",
            "loss = 299.9407043457031\n",
            "loss = 300.0177001953125\n",
            "loss = 300.10455322265625\n",
            "loss = 300.06378173828125\n",
            "loss = 300.0339050292969\n",
            "loss = 300.0625915527344\n",
            "loss = 300.0522766113281\n",
            "loss = 300.18377685546875\n",
            "loss = 300.0719909667969\n",
            "loss = 299.9042053222656\n",
            "loss = 300.00531005859375\n",
            "loss = 300.0200500488281\n",
            "loss = 300.0132141113281\n",
            "loss = 299.9716491699219\n",
            "loss = 299.9391174316406\n",
            "loss = 299.9500427246094\n",
            "loss = 300.0241394042969\n",
            "loss = 299.9303283691406\n",
            "loss = 300.0099182128906\n",
            "loss = 299.9608154296875\n",
            "loss = 300.11395263671875\n",
            "loss = 300.01617431640625\n",
            "loss = 299.9592590332031\n",
            "loss = 300.02777099609375\n",
            "loss = 299.9214172363281\n",
            "loss = 299.8809814453125\n",
            "loss = 299.96923828125\n",
            "loss = 300.02349853515625\n",
            "loss = 300.0154113769531\n",
            "loss = 300.023193359375\n",
            "loss = 299.9596252441406\n",
            "loss = 299.9010009765625\n",
            "loss = 299.9242248535156\n",
            "loss = 300.0202941894531\n",
            "loss = 299.9353332519531\n",
            "loss = 300.0469055175781\n",
            "loss = 299.9593505859375\n",
            "loss = 300.0941162109375\n",
            "loss = 299.9636535644531\n",
            "loss = 299.90826416015625\n",
            "loss = 299.9922180175781\n",
            "loss = 299.996826171875\n",
            "loss = 300.0894775390625\n",
            "loss = 299.9521789550781\n",
            "loss = 300.0450134277344\n",
            "loss = 299.9810791015625\n",
            "loss = 300.0066223144531\n",
            "loss = 300.0550537109375\n",
            "loss = 300.0037841796875\n",
            "loss = 299.97821044921875\n",
            "loss = 299.99853515625\n",
            "loss = 299.9645080566406\n",
            "loss = 300.0133361816406\n",
            "loss = 300.1450500488281\n",
            "loss = 300.0234069824219\n",
            "loss = 299.9779357910156\n",
            "loss = 299.9176025390625\n",
            "loss = 300.06793212890625\n",
            "loss = 299.9410400390625\n",
            "loss = 300.009521484375\n",
            "loss = 300.0399169921875\n",
            "loss = 299.986083984375\n",
            "loss = 300.0685119628906\n",
            "loss = 300.0260925292969\n",
            "loss = 300.0057373046875\n",
            "loss = 299.9296875\n",
            "loss = 300.1278381347656\n",
            "loss = 299.98486328125\n",
            "loss = 299.9638977050781\n",
            "loss = 299.9931335449219\n",
            "loss = 300.06243896484375\n",
            "loss = 300.08575439453125\n",
            "loss = 300.1592712402344\n",
            "loss = 300.13507080078125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRlkcpT0D-a1"
      },
      "source": [
        "## MNIST Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4GfdMRhD-a1"
      },
      "source": [
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyQ4gP46D-a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "59ac615d27ac4a8a9e16f26d226f2a87",
            "c17884873f104da681a369aef07cd7ed",
            "4b234d4d1ed449a69c7a707f156abf09",
            "ccc84a48be774014a1fbca524529d3f2",
            "3ece9a70cd474541854c4e53f7ac32c6",
            "4e8a029703274f02916c51f0414bf9c6",
            "bdac665fdaa14c03880719df12671f5a",
            "c2b5c9f6a0b449a5aa04aa2c143a093c",
            "feb6cbb0108e49f8a64d62371e2f0717",
            "eb2ff08432ce42889b9283135388dd2a",
            "cca56bc8507546928fa759d6200e5dc5",
            "d5eb2a80c81b40b3840778d4bd7901a9",
            "7b3cfc902cf44ac0af7a4a7703eeac67",
            "0748f10e07c445fb8db186488d3f4872",
            "b92f1d855f694190978d134a05b638ff",
            "4adeb1848d0f45809200fcf7ec4e83d0",
            "2665ef3e02f644a1ab533dab13266c6c",
            "c51aa6d3d3a54b15b7f01a7154e97230",
            "d3a58daa0572413fafb07e18df147ab2",
            "170efb9d9772481d9e3d59a8b0cc0b66",
            "595e6ce405154cca9cc3153db6044d42",
            "3b992aac426545809a37ddc4d8ac01fd",
            "9ad73e1f567f49ab8e3411cdd572aae4",
            "68f5123da480472d95dc3fe5f5e4f453",
            "e40d1aa0116a462da610741c3a9c65a2",
            "406e01c5c1aa414297db5516060e0af7",
            "afa9a9964b924b9aae9fb4bec7684cb2",
            "0020949becbf48ac9cdddaf4f075ce5c",
            "ccddde088f8443e69d3ec102bae7eb5d",
            "fb535e2a37e04b4785b53964c8fe3ac9",
            "4803189e444b4c908266204e6d79e906",
            "04ca90ad283642849438872b4b382aff"
          ]
        },
        "outputId": "9f2af01c-b9ca-4547-afa4-5f5ded0b6b75"
      },
      "source": [
        "data = MNIST(\".\",download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59ac615d27ac4a8a9e16f26d226f2a87",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "feb6cbb0108e49f8a64d62371e2f0717",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2665ef3e02f644a1ab533dab13266c6c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e40d1aa0116a462da610741c3a9c65a2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdfX2XnGD-a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14b73682-3f6a-4988-ff83-2b2ba5fe1c6b"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7fwSvMkD-a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "98539590-fe18-4831-f696-cb3dc1e0563c"
      },
      "source": [
        "import numpy as np\n",
        "img,y = data[np.random.randint(1,60000)]\n",
        "print(y)\n",
        "img"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAArUlEQVR4nGNgGBmAEY3PJSfHd0VM7gzDw+8Yaosu/v379++/v3//XmBgYGBBkess/VzykYGB8T8Dwy00bUxGT95m4rKf5/5fK5yOW/T377vOSByS3TtX/f33IwmnZgbbZ/+EccteO8CKJpLbJAFlaX78i65z0981IRIMDAzsxe9/+TOhSfKl3//77Mjhw2f+/juMza7+w////fv3vAhZDCng1RkYGD6+wO3UwQ4AJjM/nLiVs7sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F0C515790B8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3giZTnRiD-a-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f8277f-719c-48cf-de6d-43467a9c9ea2"
      },
      "source": [
        "data.train_data[2].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsZHdAMlD-a_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d365182-115f-4c0d-e60e-dff7c9a4c9b2"
      },
      "source": [
        "data.train_labels[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROmpaSMVD-bA"
      },
      "source": [
        "### MNIST Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHhKarpfD-bB"
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(784, 100),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(100, 100),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(100, 10),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8Q59QCED-bC"
      },
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehneQZatD-bG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6094995d-326e-48f1-b853-1bec6beff826"
      },
      "source": [
        "sample = np.random.choice(range(len(data.train_data)),1000)\n",
        "x = data.train_data[sample].reshape(1000,-1).float()/255\n",
        "yt = data.train_labels[sample]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucZS9UPAD-bJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7abafa7-7a83-4dbf-e026-a24a254181d6"
      },
      "source": [
        "x.shape,yt.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1000, 784]), torch.Size([1000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdOxW-tYD-bK"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)\n",
        "losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMtNhgaED-bL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "15e52594-c5ba-4776-a82d-274a0603f7bc"
      },
      "source": [
        "for i in range(100):\n",
        "    \n",
        "    sample = np.random.choice(range(len(data.train_data)),1000)\n",
        "    x = data.train_data[sample].reshape(1000,-1).float()/255\n",
        "    yt = data.train_labels[sample]\n",
        "    \n",
        "    y = model(x)\n",
        "    loss = loss_fn(y,yt)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    losses+=[loss.item()]\n",
        "    print( f\"loss = {loss}\")\n",
        "plt.plot(losses);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss = 2.3091886043548584\n",
            "loss = 2.421633243560791\n",
            "loss = 2.746687173843384\n",
            "loss = 1.8758249282836914\n",
            "loss = 1.418844223022461\n",
            "loss = 1.181101679801941\n",
            "loss = 0.8480774164199829\n",
            "loss = 0.8853127360343933\n",
            "loss = 0.6826867461204529\n",
            "loss = 0.6943345069885254\n",
            "loss = 0.8329158425331116\n",
            "loss = 0.5288072228431702\n",
            "loss = 0.5125091671943665\n",
            "loss = 0.4641791582107544\n",
            "loss = 0.46357011795043945\n",
            "loss = 0.3807067275047302\n",
            "loss = 0.3886590003967285\n",
            "loss = 0.40529558062553406\n",
            "loss = 0.3502967655658722\n",
            "loss = 0.333193302154541\n",
            "loss = 0.32881617546081543\n",
            "loss = 0.35097938776016235\n",
            "loss = 0.3163655400276184\n",
            "loss = 0.29873159527778625\n",
            "loss = 0.2948206067085266\n",
            "loss = 0.26398730278015137\n",
            "loss = 0.31777969002723694\n",
            "loss = 0.2856494188308716\n",
            "loss = 0.3361603617668152\n",
            "loss = 0.31251996755599976\n",
            "loss = 0.2660728394985199\n",
            "loss = 0.277740478515625\n",
            "loss = 0.23137842118740082\n",
            "loss = 0.30541470646858215\n",
            "loss = 0.18123957514762878\n",
            "loss = 0.24073462188243866\n",
            "loss = 0.2456580400466919\n",
            "loss = 0.25232651829719543\n",
            "loss = 0.223764568567276\n",
            "loss = 0.22647342085838318\n",
            "loss = 0.23693320155143738\n",
            "loss = 0.27611052989959717\n",
            "loss = 0.22515827417373657\n",
            "loss = 0.21269597113132477\n",
            "loss = 0.19896452128887177\n",
            "loss = 0.18863694369792938\n",
            "loss = 0.20588985085487366\n",
            "loss = 0.21070294082164764\n",
            "loss = 0.21749413013458252\n",
            "loss = 0.21227671205997467\n",
            "loss = 0.1733785718679428\n",
            "loss = 0.19071954488754272\n",
            "loss = 0.17862960696220398\n",
            "loss = 0.18768718838691711\n",
            "loss = 0.18982459604740143\n",
            "loss = 0.20553071796894073\n",
            "loss = 0.193038672208786\n",
            "loss = 0.17172501981258392\n",
            "loss = 0.23650409281253815\n",
            "loss = 0.18689721822738647\n",
            "loss = 0.1538161188364029\n",
            "loss = 0.12906919419765472\n",
            "loss = 0.18230819702148438\n",
            "loss = 0.2208704650402069\n",
            "loss = 0.15914881229400635\n",
            "loss = 0.15103735029697418\n",
            "loss = 0.17537669837474823\n",
            "loss = 0.18600881099700928\n",
            "loss = 0.12864695489406586\n",
            "loss = 0.12564873695373535\n",
            "loss = 0.1625543236732483\n",
            "loss = 0.19141986966133118\n",
            "loss = 0.14431381225585938\n",
            "loss = 0.13916799426078796\n",
            "loss = 0.14890427887439728\n",
            "loss = 0.14982780814170837\n",
            "loss = 0.15055759251117706\n",
            "loss = 0.17239955067634583\n",
            "loss = 0.14965298771858215\n",
            "loss = 0.1588614284992218\n",
            "loss = 0.15476050972938538\n",
            "loss = 0.17062945663928986\n",
            "loss = 0.12311314791440964\n",
            "loss = 0.21783828735351562\n",
            "loss = 0.138644278049469\n",
            "loss = 0.12769284844398499\n",
            "loss = 0.1685619354248047\n",
            "loss = 0.1250191479921341\n",
            "loss = 0.13595183193683624\n",
            "loss = 0.13914898037910461\n",
            "loss = 0.13003069162368774\n",
            "loss = 0.14011482894420624\n",
            "loss = 0.14478297531604767\n",
            "loss = 0.11166273802518845\n",
            "loss = 0.15119656920433044\n",
            "loss = 0.13130401074886322\n",
            "loss = 0.12286452203989029\n",
            "loss = 0.14902831614017487\n",
            "loss = 0.09727341681718826\n",
            "loss = 0.1508398801088333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BAXeaKHD-bM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "176051a4-c69e-43f7-f2b2-d4f8d89f1e12"
      },
      "source": [
        "x_test = data.train_data[-1000:].reshape(1000,-1).float()/255\n",
        "y_test = data.train_labels[-1000:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VXFOBCjD-bO"
      },
      "source": [
        "with torch.no_grad():\n",
        "    y_pred = model(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt0c-JhpD-bP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c09df1c8-51bd-4874-a76a-7108bf233ace"
      },
      "source": [
        "print(\"Accuracy = \", (y_pred.argmax(dim=1) == y_test).sum().float().item()/1000.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY6m7c0qD-bQ"
      },
      "source": [
        "## Course Conclusion\n",
        "\n",
        "By now you should have a sufficient introduction to the various ways one can use python for scientific computing. The best way to learn more is to start using python for whatever project you are working on. Only practice will make you comfortable with using python.\n"
      ]
    }
  ]
}